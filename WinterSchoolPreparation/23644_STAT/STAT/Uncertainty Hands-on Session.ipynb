{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on exercise\n",
    "\n",
    "Model setup is as follows: we have dijet asymmetry data prepared, where the asymmetry $A_J$ is defined as the difference between the two jets divided by the sum. Specifically,\n",
    "\n",
    "$$A_{\\mathrm{J}} = \\frac{p_{\\mathrm{T, 1}} - p_{\\mathrm{T, 2}}}{p_{\\mathrm{T, 1}} + p_{\\mathrm{T, 2}}}$$\n",
    "\n",
    "We will construct a model to describe the energy loss observed in the dijet asymmetry.  For this model, we consider back-to-back dijets.  Each jet can lose energy, and the lost energy is parameterized as\n",
    "\n",
    "$$ \\Delta p_{\\mathrm{T}} / p_{\\mathrm{T}} \\sim A \\times Gaus(1, 1)$$\n",
    "\n",
    "In addition to the energy loss contribution, we have extra \"apparent\" smearing on the $A_J$ coming from the fact that we have other processes going on in the events (three jets etc).  It is parameterized as a Gaussian smearing on $A_J$ with width $B$. So there are two total parameters: $A$ and $B$.\n",
    "\n",
    "The measurement is done in two bins of centrality.  One in central event, where ($A$, $B$) are all relevant, and another one in very peripheral event, where only the parameter ($B$) is relevant.\n",
    "\n",
    "\n",
    "## Loading python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor as GPR\n",
    "from sklearn.gaussian_process import kernels\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import lapack\n",
    "from scipy import stats\n",
    "import emcee\n",
    "import numpy as np\n",
    "\n",
    "import importlib\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import src.reader as Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: prepare input file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load stuff from text files\n",
    "\n",
    "The `Reader` class implements the interface between input data files and the code.  There are functions to read in experimental data, externally-supplied covariance matrix, design points, and calculations for the design points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data files\n",
    "RawData1 = Reader.ReadData('input/AJExample/Data_Selection1.dat')   # Central bin data\n",
    "RawData2 = Reader.ReadData('input/AJExample/Data_Selection2.dat')   # Peripheral bin data\n",
    "\n",
    "# Read covariance -- if you have covariance matrix from the experiments for example\n",
    "# RawCov1 = Reader.ReadCovariance('input/AJExample/______.dat')\n",
    "# RawCov2 = Reader.ReadCovariance('input/AJExample/______.dat')\n",
    "\n",
    "# Read design points\n",
    "RawDesign = Reader.ReadDesign('input/AJExample/Design.dat')   # Design points!\n",
    "\n",
    "# Read model prediction\n",
    "RawPrediction1 = Reader.ReadPrediction('input/AJExample/Prediction_Selection1.dat')   # Calculation for central bin\n",
    "RawPrediction2 = Reader.ReadPrediction('input/AJExample/Prediction_Selection2.dat')   # Calculation for peripheral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup analysis\n",
    "\n",
    "In addition to reading stuff, there is also a `EstimateCovariance` function that estimates the covariance for you.  It is configurable to do different correlation treatment for different systematic uncertainty sources (and then add them all up!).  We can also correlate across different measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty dictionary\n",
    "AllData = {}\n",
    "\n",
    "C0 = 'Central'\n",
    "C1 = 'Peripheral'\n",
    "\n",
    "# Basic information\n",
    "AllData[\"systems\"] = [\"PbPb5020\"]                 # List of collision systems we are doing\n",
    "AllData[\"keys\"] = RawDesign[\"Parameter\"]          # Get the \"A\" and \"B\" from the design file\n",
    "AllData[\"labels\"] = RawDesign[\"Parameter\"]        # Get the \"A\" and \"B\" from the design file\n",
    "AllData[\"ranges\"] = [(0, 0.3), (0, 0.3)]          # Range of A and B\n",
    "AllData[\"observables\"] = [('A_J', [C0, C1])]      # We measure A_J with two bins: \"Central\" and \"Peripheral\"\n",
    "# In this example \"C0\" is central data, and \"C1\" is peripheral => see above\n",
    "\n",
    "# Data points\n",
    "Data = {\"PbPb5020\": {\"A_J\": {C0: RawData1[\"Data\"], C1: RawData2[\"Data\"]}}}\n",
    "\n",
    "# Model predictions\n",
    "Prediction = {\"PbPb5020\": {\"A_J\": {C0: {\"Y\": RawPrediction1[\"Prediction\"], \"x\": RawData1[\"Data\"]['x']},\n",
    "                                   C1: {\"Y\": RawPrediction2[\"Prediction\"], \"x\": RawData2[\"Data\"]['x']}}}}\n",
    "\n",
    "# Correlation length toggles\n",
    "# Change to 9999 to make it fully correlated,or -1 for fully uncorrelated\n",
    "# Also try 0.1 for partially correlated\n",
    "CorrelationLength = -1\n",
    "OffDiagonalCorrelationLength = -1\n",
    "\n",
    "# Covariance matrices - the indices are [system][measurement1][measurement2], each one is a block of matrix\n",
    "Covariance = Reader.InitializeCovariance(Data)\n",
    "Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C0)] = Reader.EstimateCovariance(RawData1, RawData1, SysLength = {\"default\": CorrelationLength}, ScaleX = False)\n",
    "Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C1)] = Reader.EstimateCovariance(RawData2, RawData2, SysLength = {\"default\": CorrelationLength}, ScaleX = False)\n",
    "Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C1)] = Reader.EstimateCovariance(RawData1, RawData2, SysLength = {\"default\": OffDiagonalCorrelationLength}, ScaleX = False)\n",
    "Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C0)] = Reader.EstimateCovariance(RawData2, RawData1, SysLength = {\"default\": OffDiagonalCorrelationLength}, ScaleX = False)\n",
    "\n",
    "# Assign data to the dictionary\n",
    "AllData[\"design\"] = RawDesign[\"Design\"]\n",
    "AllData[\"model\"] = Prediction\n",
    "AllData[\"data\"] = Data\n",
    "AllData[\"cov\"] = Covariance\n",
    "\n",
    "# Save to the desired file\n",
    "with open('input/default.p', 'wb') as handle:\n",
    "    pickle.dump(AllData, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot the input data!\n",
    "\n",
    "SystemCount = len(AllData[\"systems\"])\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * SystemCount), ncols = 2, nrows = 1)\n",
    "\n",
    "for s2 in range(0, 2):\n",
    "    axes[s2].set_xlabel(r\"$A_{J}$\")\n",
    "    axes[s2].set_ylabel(r\"$dN/dA_{J}$\")\n",
    "        \n",
    "    S1 = AllData[\"systems\"][0]\n",
    "    O  = AllData[\"observables\"][0][0]\n",
    "    S2 = AllData[\"observables\"][0][1][s2]\n",
    "        \n",
    "    DX = AllData[\"data\"][S1][O][S2]['x']\n",
    "    DY = AllData[\"data\"][S1][O][S2]['y']\n",
    "    DE = np.sqrt(AllData[\"data\"][S1][O][S2]['yerr']['stat'][:,0]**2 + AllData[\"data\"][S1][O][S2]['yerr']['sys'][:,0]**2)\n",
    "                \n",
    "    axes[s2].errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "axes[0].set_title('Central')\n",
    "axes[1].set_title('Peripheral')\n",
    "    \n",
    "plt.tight_layout(True)\n",
    "figure.savefig('InputData.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot 2D scatter plot of the design points\n",
    "figure, axis = plt.subplots(figsize = (5, 5), ncols = 1, nrows = 1)\n",
    "axis.plot(AllData[\"design\"][:,0], AllData[\"design\"][:,1], 'o')\n",
    "axis.set_xlabel('A')\n",
    "axis.set_ylabel('B')\n",
    "figure.savefig('DesignPoints.pdf', dpi = 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the input data overlaid on top of the design point calculations\n",
    "\n",
    "TempPrediction = AllData[\"model\"]\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * SystemCount), ncols = 2, nrows = 1)\n",
    "\n",
    "for s2 in range(0, 2):\n",
    "    axes[s2].set_xlabel(r\"$A_{J}$\")\n",
    "    axes[s2].set_ylabel(r\"$dN/dA_{J}$\")\n",
    "        \n",
    "    S1 = AllData[\"systems\"][0]\n",
    "    O  = AllData[\"observables\"][0][0]\n",
    "    S2 = AllData[\"observables\"][0][1][s2]\n",
    "        \n",
    "    DX = AllData[\"data\"][S1][O][S2]['x']\n",
    "    DY = AllData[\"data\"][S1][O][S2]['y']\n",
    "    DE = np.sqrt(AllData[\"data\"][S1][O][S2]['yerr']['stat'][:,0]**2 + AllData[\"data\"][S1][O][S2]['yerr']['sys'][:,0]**2)\n",
    "                \n",
    "    for i, y in enumerate(TempPrediction[S1][O][S2]['Y']):\n",
    "        axes[s2].plot(DX, y, 'b-', alpha=0.1, label=\"Posterior\" if i==0 else '')\n",
    "    axes[s2].errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "axes[0].set_title('Central')\n",
    "axes[1].set_title('Peripheral')\n",
    "    \n",
    "plt.tight_layout(True)\n",
    "figure.savefig('Design.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the covariance matrix\n",
    "\n",
    "MaxValue = np.array(\n",
    "    [Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C0)].max(),\n",
    "     Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C1)].max(),\n",
    "     Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C0)].max(),\n",
    "     Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C1)].max()]).max()\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (6, 6), ncols = 2, nrows = 2)\n",
    "axes[0][0].imshow(Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C0)], vmin=0, vmax=MaxValue)\n",
    "axes[0][1].imshow(Covariance[\"PbPb5020\"][(\"A_J\", C0)][(\"A_J\", C1)], vmin=0, vmax=MaxValue)\n",
    "axes[1][0].imshow(Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C0)], vmin=0, vmax=MaxValue)\n",
    "axes[1][1].imshow(Covariance[\"PbPb5020\"][(\"A_J\", C1)][(\"A_J\", C1)], vmin=0, vmax=MaxValue)\n",
    "\n",
    "axes[0][0].set_xlabel('Central')\n",
    "axes[0][1].set_xlabel('Central')\n",
    "axes[1][0].set_xlabel('Peripheral')\n",
    "axes[1][1].set_xlabel('Peripheral')\n",
    "\n",
    "axes[0][0].set_ylabel('Central')\n",
    "axes[0][1].set_ylabel('Peripheral')\n",
    "axes[1][0].set_ylabel('Central')\n",
    "axes[1][1].set_ylabel('Peripheral')\n",
    "\n",
    "figure.savefig('Covariance.pdf', dpi = 192)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean past files so that they don't haunt us later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean past MCMC samples\n",
    "if os.path.exists('cache/mcmc_chain.hdf'):\n",
    "    os.remove(\"cache/mcmc_chain.hdf\")\n",
    "\n",
    "# Clean past emulator\n",
    "for system in AllData[\"systems\"]:\n",
    "    if os.path.exists('cache/emulator/' + system + \".pkl\"):\n",
    "        os.remove('cache/emulator/' + system + \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: run emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train emulator with 8 principle components\n",
    "! python3 -m src.emulator --retrain --npc 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in emulator object into this notebook for plotting purposes\n",
    "from src import lazydict, emulator\n",
    "EmulatorPbPb5020 = emulator.Emulator.from_cache('PbPb5020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test running some prediction to see if things make sense\n",
    "# Try [0.0, 0.25], [0.1, 0.0], [0.2, 0.1], etc\n",
    "# Note the maximum range is 0.3.  What will happen if you put something larger than 0.3?  For example [0.1, 0.5]\n",
    "\n",
    "Prediction = {\"PbPb5020\": EmulatorPbPb5020.predict([[0.0, 0.25]])}\n",
    "\n",
    "SystemCount = len(AllData[\"systems\"])\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * SystemCount), ncols = 2, nrows = 1)\n",
    "\n",
    "for s2 in range(0, 2):\n",
    "    axes[s2].set_xlabel(r\"$A_{J}$\")\n",
    "    axes[s2].set_ylabel(r\"$dN/dA_{J}$\")\n",
    "        \n",
    "    S1 = AllData[\"systems\"][0]\n",
    "    O  = AllData[\"observables\"][0][0]\n",
    "    S2 = AllData[\"observables\"][0][1][s2]\n",
    "        \n",
    "    DX = AllData[\"data\"][S1][O][S2]['x']\n",
    "    DY = AllData[\"data\"][S1][O][S2]['y']\n",
    "    DE = np.sqrt(AllData[\"data\"][S1][O][S2]['yerr']['stat'][:,0]**2 + AllData[\"data\"][S1][O][S2]['yerr']['sys'][:,0]**2)\n",
    "    \n",
    "    axes[s2].plot(DX, Prediction[S1][O][S2][0], 'b-', alpha=1, label=\"Posterior\" if i==0 else '')\n",
    "    axes[s2].errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "    \n",
    "axes[0].set_title('Central')\n",
    "axes[1].set_title('Peripheral')\n",
    "\n",
    "plt.tight_layout(True)\n",
    "figure.savefig('PredictionTest.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: MCMC sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('cache/mcmc_chain.hdf'):\n",
    "    os.remove(\"cache/mcmc_chain.hdf\")\n",
    "! python3 -m src.mcmc --nwalkers 100 --nburnsteps 200 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load posterior samples into the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "src.Initialize()\n",
    "from src import mcmc\n",
    "chain = mcmc.Chain()\n",
    "MCMCSamples = chain.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: adding some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walker vs step\n",
    "\n",
    "Names = AllData[\"labels\"]\n",
    "\n",
    "with chain.dataset() as d:\n",
    "    W = d.shape[0]     # number of walkers\n",
    "    S = d.shape[1]     # number of steps\n",
    "    N = d.shape[2]     # number of paramters\n",
    "    T = int(S / 100)   # \"thinning\"\n",
    "    A = 20 / W\n",
    "    figure, axes = plt.subplots(figsize = (15, 2 * N), ncols = 1, nrows = N)\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.set_ylabel(Names[i])\n",
    "        ax.set_xlabel('Step')\n",
    "        for j in range(0, W):\n",
    "            ax.plot(range(0, S, T), d[j, ::T, i], alpha = A)\n",
    "    plt.tight_layout(True)\n",
    "    plt.savefig('MCMCSamples.pdf', dpi = 192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NDimension = len(AllData[\"labels\"])\n",
    "Ranges = np.array(AllData[\"ranges\"]).T\n",
    "figure, axes = plt.subplots(figsize = (3 * NDimension, 3 * NDimension), ncols = NDimension, nrows = NDimension)\n",
    "Names = AllData[\"labels\"]\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        if i==j:\n",
    "            ax.hist(MCMCSamples[:,i], bins=50,\n",
    "                    range=Ranges[:,i], histtype='step', color='green')\n",
    "            ax.set_xlabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "        if i>j:\n",
    "            ax.hist2d(MCMCSamples[:, j], MCMCSamples[:, i], \n",
    "                      bins=50, range=[Ranges[:,j], Ranges[:,i]], \n",
    "                      cmap='Greens')\n",
    "            ax.set_xlabel(Names[j])\n",
    "            ax.set_ylabel(Names[i])\n",
    "            ax.set_xlim(*Ranges[:,j])\n",
    "            ax.set_ylim(*Ranges[:,i])\n",
    "        if i<j:\n",
    "            ax.axis('off')\n",
    "plt.tight_layout(True)\n",
    "plt.savefig('Correlation.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Examples = MCMCSamples[ np.random.choice(range(len(MCMCSamples)), 2000), :]\n",
    "\n",
    "TempPrediction = {\"PbPb5020\": EmulatorPbPb5020.predict(Examples)}\n",
    "\n",
    "SystemCount = len(AllData[\"systems\"])\n",
    "\n",
    "figure, axes = plt.subplots(figsize = (15, 5 * SystemCount), ncols = 2, nrows = 1)\n",
    "\n",
    "for s2 in range(0, 2):\n",
    "    axes[s2].set_xlabel(r\"$A_{J}$\")\n",
    "    axes[s2].set_ylabel(r\"$dN/dA_{J}$\")\n",
    "        \n",
    "    S1 = AllData[\"systems\"][0]\n",
    "    O  = AllData[\"observables\"][0][0]\n",
    "    S2 = AllData[\"observables\"][0][1][s2]\n",
    "        \n",
    "    DX = AllData[\"data\"][S1][O][S2]['x']\n",
    "    DY = AllData[\"data\"][S1][O][S2]['y']\n",
    "    DE = np.sqrt(AllData[\"data\"][S1][O][S2]['yerr']['stat'][:,0]**2 + AllData[\"data\"][S1][O][S2]['yerr']['sys'][:,0]**2)\n",
    "\n",
    "    for i, y in enumerate(TempPrediction[S1][O][S2]):\n",
    "        axes[s2].plot(DX, y, 'b-', alpha=0.005, label=\"Posterior\" if i==0 else '')\n",
    "    axes[s2].errorbar(DX, DY, yerr = DE, fmt='ro', label=\"Measurements\")\n",
    "\n",
    "axes[0].set_title('Central')\n",
    "axes[1].set_title('Peripheral')\n",
    "    \n",
    "plt.tight_layout(True)\n",
    "figure.savefig('ObservablePosterior.pdf', dpi = 192)\n",
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close all plots to save memory\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
